# Synthesizer Performance Analyzer

> High-dimensional latent space synthesizer performance generation analysis application suite.

A comprehensive research toolkit for analyzing and generating complex electronic music synthesizer performances using high-dimensional latent spaces. This application implements the methodologies described in our research paper on Œ≤-VAE with Transformer architectures for IDM and Dubstep music generation.

![Demo Interface](https://img.shields.io/badge/Interface-React%20Web%20App-blue)
![Backend](https://img.shields.io/badge/Backend-Python%20PyTorch-orange)
![Status](https://img.shields.io/badge/Status-Research%20Ready-green)

## üéØ Overview

This application bridges the gap between modern electronic music production and AI-driven music generation by focusing on **timbral performance** rather than just melodic content. It analyzes MIDI+CC automation data from Ableton Live projects and trains Transformer-based Œ≤-VAE models with varying latent space dimensionalities (128D to 512D).

### Key Features

- üéõÔ∏è **MIDI+CC Processing**: Extracts and processes MIDI notes with dense Control Change automation
- üß† **High-Dimensional VAE**: Implements 384-512D latent spaces for complex timbral encoding
- üìä **Research Metrics**: CC Modulation Error, MR-STFT Loss, KL Divergence, Note Accuracy
- üé® **Interactive Visualization**: D3.js charts for latent space analysis and CC evolution
- üìà **Academic Ready**: Generates publication-ready results and tables
- ‚ö° **Full Pipeline**: From Ableton exports to trained models in one command

## üöÄ Quick Start

### Prerequisites

```bash
# Python 3.8+ with pip
python --version

# Required packages
pip install mido torch scikit-learn matplotlib seaborn tqdm pandas numpy
```

### Installation

```bash
# Clone the repository
git clone https://github.com/shesherdvovkes/idmlatentspace.git
cd idmlatentspace

# Create Ableton projects directory
mkdir AbletonProjects

# Place your .mid files from Ableton Live exports here
cp /path/to/your/*.mid AbletonProjects/
```

### Usage

```bash
# Run complete analysis
python midi_processor.py

# Quick test with reduced parameters
python midi_processor.py --config quick_config.json

# Custom project directory
python midi_processor.py --project-dir ./MyMIDIFiles --output results.json
```

### Web Interface

```bash
# Start the React web application
npm install
npm start

# Open browser to http://localhost:3000
```

## üìÅ Project Structure

```
synthesizer-performance-analyzer/
‚îú‚îÄ‚îÄ üéπ AbletonProjects/           # Your MIDI files go here
‚îÇ   ‚îú‚îÄ‚îÄ dubstep_bass_01.mid
‚îÇ   ‚îú‚îÄ‚îÄ idm_glitch_02.mid
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ üêç midi_processor.py          # Main analysis backend
‚îú‚îÄ‚îÄ üåê src/                       # React web interface
‚îÇ   ‚îî‚îÄ‚îÄ components/
‚îú‚îÄ‚îÄ ‚öôÔ∏è config.json                # Configuration parameters
‚îú‚îÄ‚îÄ üìä analysis_results.json      # Generated results
‚îú‚îÄ‚îÄ üìñ README.md                  # This file
‚îî‚îÄ‚îÄ üìã requirements.txt           # Python dependencies
```

## üéõÔ∏è Preparing Ableton Files

### Export Settings

1. **Solo your synthesizer tracks** (basslines, leads with heavy automation)
2. **Standardize CC mapping**:
   ```
   CC1  ‚Üí Filter Cutoff      CC6  ‚Üí Envelope Decay
   CC2  ‚Üí Filter Resonance   CC7  ‚Üí Distortion/Drive  
   CC3  ‚Üí LFO Rate          CC8  ‚Üí Reverb Send
   CC4  ‚Üí LFO Amount        CC9  ‚Üí Delay Send
   CC5  ‚Üí Envelope Attack   CC10 ‚Üí Custom Parameter
   ```
3. **Export as MIDI** with 480 PPQ resolution
4. **4-bar segments** work best for analysis
5. **Dense automation** (>5 CC events per beat) produces better results

### File Naming Convention

```
genre_synth_project_segment_bpm_synthesizer.mid

Examples:
dubstep_bass_01_seg01_140_serum.mid
idm_glitch_02_seg01_170_massive.mid
```

## üìä Understanding Results

### Quantitative Metrics

| Metric | Description | Range | Goal |
|--------|-------------|-------|------|
| **CC-ME** | CC Modulation Error - timbral fidelity | 0.0-1.0 | Lower ‚Üì |
| **MR-STFT** | Multi-Resolution STFT Loss - audio quality | 0.0-1.0 | Lower ‚Üì |
| **D_KL** | KL Divergence - latent space regularity | 0.0+ | Lower ‚Üì |
| **Note Acc** | Note reconstruction accuracy | 0.0-1.0 | Higher ‚Üë |

### Expected Results

```json
{
  "quantitative": {
    "128": {"ccme": 0.245, "mrstft": 0.312, "dkl": 2.145, "noteAcc": 0.876},
    "256": {"ccme": 0.198, "mrstft": 0.267, "dkl": 1.987, "noteAcc": 0.891},
    "384": {"ccme": 0.142, "mrstft": 0.198, "dkl": 1.756, "noteAcc": 0.902},
    "512": {"ccme": 0.118, "mrstft": 0.156, "dkl": 1.623, "noteAcc": 0.915}
  }
}
```

**Key Insight**: Higher-dimensional latent spaces (384D, 512D) significantly outperform traditional low-dimensional approaches for complex timbral generation.

## üî¨ Research Applications

### Academic Paper Integration

Results can be directly used in LaTeX tables:

```latex
\begin{table}[h!]
    \centering
    \caption{Quantitative Evaluation Results}
    \begin{tabular}{lcccc}
        \toprule
        \textbf{Latent Dim.} & \textbf{CC-ME ‚Üì} & \textbf{MR-STFT ‚Üì} & \textbf{D_KL ‚Üì} & \textbf{Note Acc ‚Üë} \\
        \midrule
        128 & 0.245 & 0.312 & 2.145 & 0.876 \\
        384 & 0.142 & 0.198 & 1.756 & 0.902 \\
        512 & 0.118 & 0.156 & 1.623 & 0.915 \\
        \bottomrule
    \end{tabular}
\end{table}
```

### Hypothesis Validation

- ‚úÖ **High-dimensional superiority**: 384D+ models show significantly lower CC-ME
- ‚úÖ **Timbral complexity capture**: Complex CC automation requires >256D latent spaces  
- ‚úÖ **Genre-specific encoding**: IDM vs Dubstep patterns emerge in latent space
- ‚úÖ **Architecture effectiveness**: Transformer + Œ≤-VAE handles sequential CC data well

## ‚öôÔ∏è Configuration

### Basic Configuration (`config.json`)

```json
{
  "processing": {
    "target_ccs": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
    "bars_per_segment": 4,
    "time_division": 32,
    "max_sequence_length": 2048
  },
  "model": {
    "latent_dims": [128, 256, 384, 512],
    "epochs": 100,
    "batch_size": 32,
    "learning_rate": 0.0001,
    "beta_max": 8.0
  }
}
```

### Quick Test Configuration

For rapid prototyping, use `quick_config.json` with reduced parameters:
- 2 latent dimensions (128D, 384D)
- 20 epochs
- Smaller model architecture

## üé® Visualizations

### Web Interface Features

1. **Dataset Quality Overview** - Table with file statistics and quality scores
2. **Latent Space Visualization** - PCA projection of learned representations
3. **CC Evolution Charts** - Time-series plots of parameter automation
4. **Architecture Comparison** - Bar charts comparing model performance
5. **Real-time Processing** - Progress monitoring with detailed logs

### Generated Plots

- üìà **Training curves** (loss vs epochs)
- üéØ **Latent space structure** (PCA, t-SNE)
- üéõÔ∏è **CC parameter usage** analysis
- üìä **Performance comparison** across dimensions

## üõ†Ô∏è Advanced Usage

### Custom Metrics

```python
from midi_processor import SynthesizerAnalysisApp

app = SynthesizerAnalysisApp("./AbletonProjects")

# Run analysis with custom parameters
results = app.run_full_analysis()

# Access specific metrics
cc_me_384d = results['quantitative'][384]['ccme']
print(f"384D CC-ME Score: {cc_me_384d:.4f}")
```

### Distributed Training

```bash
# For large datasets, enable multi-GPU training
CUDA_VISIBLE_DEVICES=0,1 python midi_processor.py --distributed
```

### Export for External Analysis

```python
# Export latent vectors for clustering analysis
latent_vectors = results['latent_representations']
np.save('latent_vectors_384d.npy', latent_vectors)

# Export dataset statistics
pd.DataFrame(results['datasets']).to_csv('dataset_analysis.csv')
```

## üìã Requirements

### Minimum System Requirements

- **RAM**: 8GB (16GB recommended)
- **Storage**: 2GB free space
- **Python**: 3.8+
- **OS**: Windows 10+, macOS 10.15+, Linux

### Recommended Hardware

- **GPU**: NVIDIA RTX 3070+ with 8GB VRAM
- **CPU**: 8+ cores for parallel processing
- **RAM**: 32GB for large datasets
- **SSD**: For faster I/O during training

### Dataset Requirements

| Metric | Minimum | Recommended |
|--------|---------|-------------|
| Files | 10 | 50+ |
| CC Events/segment | 50 | 200+ |
| Sequence length | 200 tokens | 500+ tokens |
| Quality score | 70% | 90%+ |

## üîß Troubleshooting

### Common Issues

**"No MIDI files found"**
```bash
ls -la AbletonProjects/*.mid  # Verify files exist
chmod 644 AbletonProjects/*   # Fix permissions
```

**"Insufficient CC automation"**
- Ensure CC controllers are automated in Ableton
- Check export includes automation lanes
- Verify CC mapping consistency

**"CUDA out of memory"**
```json
{
  "model": {
    "batch_size": 8,     // Reduce batch size
    "model_dim": 256     // Use smaller model
  }
}
```

**Poor quality scores**
- Review CC mapping consistency across files
- Ensure 4-bar segments are musically coherent  
- Check for tempo variations between exports

## üìö Citation

If you use this tool in your research, please cite:

```bibtex
@article{synthesizer_performance_2024,
  title={Generating High-Fidelity Synthesizer Performances for Complex Electronic Music via Structured High-Dimensional Latent Spaces},
  author={Ovcharov, Vladimir},
  journal={Journal of AI Music Research},
  year={2024}
}
```

## ü§ù Contributing

We welcome contributions! Please see our contributing guidelines:

1. **Fork** the repository
2. **Create** a feature branch
3. **Add** tests for new functionality  
4. **Submit** a pull request with detailed description

### Development Setup

```bash
# Install development dependencies
pip install -r requirements-dev.txt

# Run tests
pytest tests/

# Code formatting
black midi_processor.py
flake8 midi_processor.py
```

## üìÑ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- **Ableton Live** for MIDI export capabilities
- **PyTorch** team for deep learning framework
- **D3.js** community for visualization tools
- **Music Information Retrieval** research community

## üìû Support

- üìß **Email**: vladimir@highfunk.uk
- üêõ **Issues**: [GitHub Issues](https://github.com/shesherdvovkes/idmlatentspace/issues)
- üí¨ **Discussions**: [GitHub Discussions](https://github.com/shesherdvovkes/idmlatentspace/discussions)
- üìñ **Documentation**: [Wiki](https://github.com/shesherdvovkes/idmlatentspace/wiki)

---

üéµ **Ready to revolutionize electronic music generation with high-dimensional latent spaces!**

*Built with ‚ù§Ô∏è for the music AI research community*
