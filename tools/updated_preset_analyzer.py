#!/usr/bin/env python3
"""
–û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø—Ä–µ—Å–µ—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º SysEx Toolkit
"""

# –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ (–ø–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏)
from sysex_toolkit import SysExLibrary, SysExFormat, decode_sysex_file
import numpy as np
import json

class ModernPresetAnalyzer:
    """–°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø—Ä–µ—Å–µ—Ç–æ–≤ —Å SysEx Toolkit"""
    
    def __init__(self):
        self.sysex_library = SysExLibrary()
        
    def analyze_user_vs_factory_preset(self, user_preset_file, factory_sysex_file, baseline_name="Contra"):
        """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –±–∏–±–ª–∏–æ—Ç–µ–∫–æ–π"""
        
        print(f"üéπ –ê–Ω–∞–ª–∏–∑ —Å SysEx Toolkit v1.0.0")
        
        # 1. –ó–∞–≥—Ä—É–∑–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–µ—Å–µ—Ç
        user_presets = decode_sysex_file(user_preset_file, SysExFormat.ACCESS_VIRUS)
        
        if not user_presets:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–µ—Å–µ—Ç")
            return None
        
        user_preset = user_presets[0]
        
        # 2. –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–±—Ä–∏—á–Ω—ã–µ –ø—Ä–µ—Å–µ—Ç—ã
        decoder = self.sysex_library.get_decoder(SysExFormat.ACCESS_VIRUS)
        factory_presets = decoder.decode_sysex_file(factory_sysex_file)
        
        print(f"üì¶ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(factory_presets)} —Ñ–∞–±—Ä–∏—á–Ω—ã—Ö –ø—Ä–µ—Å–µ—Ç–æ–≤")
        
        # 3. –ù–∞–π—Ç–∏ –±–∞–∑–æ–≤—ã–π –ø—Ä–µ—Å–µ—Ç
        baseline_preset = None
        for preset in factory_presets:
            preset_name = preset['metadata'].get('preset_name', '')
            if baseline_name.lower() in preset_name.lower():
                baseline_preset = preset
                print(f"‚úÖ –ù–∞–π–¥–µ–Ω –±–∞–∑–æ–≤—ã–π: {preset_name}")
                break
        
        if not baseline_preset:
            print(f"‚ùå –ë–∞–∑–æ–≤—ã–π –ø—Ä–µ—Å–µ—Ç '{baseline_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return None
        
        # 4. –°—Ä–∞–≤–Ω–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        differences = self.compare_presets(user_preset, baseline_preset)
        
        # 5. –°–æ–∑–¥–∞—Ç—å —Ä–µ–¥—É—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ
        reduced_space = self.create_reduced_space(differences)
        
        return {
            'user_preset': user_preset,
            'baseline_preset': baseline_preset,
            'differences': differences,
            'reduced_space': reduced_space
        }
    
    def compare_presets(self, user_preset, baseline_preset, threshold=0.01):
        """–°—Ä–∞–≤–Ω–∏—Ç—å –¥–≤–∞ –ø—Ä–µ—Å–µ—Ç–∞"""
        
        user_params = user_preset['parameters']
        baseline_params = baseline_preset['parameters']
        
        significant_changes = []
        
        for param_name in user_params:
            if param_name in baseline_params:
                user_val = user_params[param_name]['normalized_value']
                baseline_val = baseline_params[param_name]['normalized_value']
                
                difference = abs(user_val - baseline_val)
                
                if difference > threshold:
                    change = {
                        'parameter': param_name,
                        'category': user_params[param_name]['category'],
                        'cc_number': user_params[param_name]['cc_number'],
                        'user_value': user_val,
                        'baseline_value': baseline_val,
                        'difference': difference,
                        'importance': self.calculate_importance(param_name, difference, user_params[param_name])
                    }
                    significant_changes.append(change)
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
        significant_changes.sort(key=lambda x: x['importance'], reverse=True)
        
        print(f"üîÑ –ù–∞–π–¥–µ–Ω–æ {len(significant_changes)} –∑–Ω–∞—á–∏–º—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π")
        
        return significant_changes
    
    def calculate_importance(self, param_name, difference, param_data):
        """–í—ã—á–∏—Å–ª–∏—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞"""
        
        importance = difference * 2.0  # –ë–∞–∑–æ–≤–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å
        
        # CC –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä—ã –≤–∞–∂–Ω–µ–µ (–º–æ–∂–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å)
        if param_data['cc_number']:
            importance += 1.5
        
        # –§–∏–ª—å—Ç—Ä–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫—Ä–∏—Ç–∏—á–Ω—ã –¥–ª—è Dubstep
        if param_data['category'] == 'filter':
            importance += 1.2
        
        # LFO –≤–∞–∂–µ–Ω –¥–ª—è –º–æ–¥—É–ª—è—Ü–∏–∏
        if param_data['category'] == 'lfo':
            importance += 1.0
        
        # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        if 'cutoff' in param_name.lower():
            importance += 2.0  # Cutoff —Å–≤–µ—Ä—Ö-–≤–∞–∂–µ–Ω
        
        return importance
    
    def create_reduced_space(self, significant_changes, target_dimensions=[32, 64, 128]):
        """–°–æ–∑–¥–∞—Ç—å —Ä–µ–¥—É—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞"""
        
        reduced_spaces = {}
        
        for dim in target_dimensions:
            selected_params = significant_changes[:dim]
            
            # –°–æ–∑–¥–∞—Ç—å –≤–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            feature_vector = []
            feature_names = []
            cc_mappings = {}
            
            for change in selected_params:
                feature_vector.append(change['user_value'])
                feature_names.append(change['parameter'])
                
                if change['cc_number']:
                    cc_mappings[f"CC{change['cc_number']}"] = change['parameter']
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç—å –¥–æ —Ü–µ–ª–µ–≤–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
            while len(feature_vector) < dim:
                feature_vector.append(0.0)
                feature_names.append(f'padding_{len(feature_names)}')
            
            reduced_spaces[f'{dim}d'] = {
                'dimension': dim,
                'feature_vector': np.array(feature_vector[:dim]),
                'feature_names': feature_names[:dim],
                'cc_mappings': cc_mappings,
                'parameters_used': len(selected_params),
                'compression_ratio': dim / 384,  # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º–∏ 384D
                'dubstep_ready': any('filter' in change['category'] for change in selected_params[:10])
            }
        
        return reduced_spaces
    
    def save_analysis_results(self, results, output_prefix='sysex_analysis'):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞"""
        
        # –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        analysis_data = {
            'metadata': {
                'user_preset_name': results['user_preset']['metadata'].get('preset_name', 'Unknown'),
                'baseline_preset_name': results['baseline_preset']['metadata'].get('preset_name', 'Unknown'),
                'total_differences': len(results['differences']),
                'sysex_toolkit_version': '1.0.0'
            },
            'differences': results['differences'],
            'reduced_spaces': {}
        }
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å numpy –≤ —Å–ø–∏—Å–∫–∏ –¥–ª—è JSON
        for space_name, space_data in results['reduced_space'].items():
            analysis_data['reduced_spaces'][space_name] = {
                **space_data,
                'feature_vector': space_data['feature_vector'].tolist()
            }
        
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å JSON
        with open(f'{output_prefix}_complete.json', 'w') as f:
            json.dump(analysis_data, f, indent=2, default=str)
        
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤–µ–∫—Ç–æ—Ä—ã –æ—Ç–¥–µ–ª—å–Ω–æ
        for space_name, space_data in results['reduced_space'].items():
            np.save(f'{output_prefix}_{space_name}.npy', space_data['feature_vector'])
        
        # –°–æ–∑–¥–∞—Ç—å –æ—Ç—á–µ—Ç
        self.create_analysis_report(results, f'{output_prefix}_report.txt')
        
        print(f"\nüíæ –ê–Ω–∞–ª–∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω:")
        print(f"   - {output_prefix}_complete.json")
        for space_name in results['reduced_space'].keys():
            print(f"   - {output_prefix}_{space_name}.npy")
        print(f"   - {output_prefix}_report.txt")
    
    def create_analysis_report(self, results, report_path):
        """–°–æ–∑–¥–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç"""
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("üéπ –û–¢–ß–ï–¢ –ê–ù–ê–õ–ò–ó–ê –ü–†–ï–°–ï–¢–û–í (SysEx Toolkit)\n")
            f.write("=" * 50 + "\n\n")
            
            # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            user_name = results['user_preset']['metadata'].get('preset_name', 'Unknown')
            baseline_name = results['baseline_preset']['metadata'].get('preset_name', 'Unknown')
            
            f.write(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–µ—Å–µ—Ç